{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:53:05.262488Z",
     "start_time": "2021-07-23T21:53:02.144280Z"
    }
   },
   "outputs": [],
   "source": [
    "#code by Tobias Gensch with contributions from Ellyn Peters, Jen Crawford, and Cian Kingston\n",
    "import os, re, sys, pickle, datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA,NMF\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectKBest,f_regression,mutual_info_regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LogisticRegression,Lasso,LinearRegression,Ridge,ElasticNetCV,ElasticNet,Lars,LassoCV,RidgeCV,LarsCV,LassoLarsCV,LassoLarsIC,OrthogonalMatchingPursuitCV,OrthogonalMatchingPursuit\n",
    "from sklearn.manifold import TSNE,MDS\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RepeatedKFold,LeaveOneOut,cross_val_score,cross_validate\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC,SVR\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "import statsmodels.api as sm\n",
    "import multiprocessing\n",
    "nproc = max([1,multiprocessing.cpu_count()-2])\n",
    "from joblib import Parallel,delayed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import loo_q2 as loo\n",
    "import ForwardStepCandidates_updated as fsc\n",
    "randomstate = 42\n",
    "\n",
    "def plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=True,sav=False,label=\"selectivity\",loo_pred=[]):\n",
    "    y_orig_min = np.min(np.hstack((y_train,y_test)))\n",
    "    y_pred_min = np.min(np.hstack((y_pred_train,y_pred_test)))\n",
    "    y_orig_max = np.max(np.hstack((y_train,y_test)))\n",
    "    y_pred_max = np.max(np.hstack((y_pred_train,y_pred_test)))\n",
    "    delta_x = 0.04 * (y_orig_max-y_orig_min)\n",
    "    delta_y = 0.04 * (y_pred_max-y_pred_min)      \n",
    "    yy_fit = np.polyfit(y_train,y_pred_train,deg=1)\n",
    "    yy_fit_line = yy_fit[1]+yy_fit[0]*y_train\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.xlim([y_orig_min-delta_x,y_orig_max+delta_x])\n",
    "    plt.ylim([y_pred_min-delta_y,y_pred_max+delta_y])\n",
    "    if len(loo_pred) != 0:\n",
    "        plt.scatter(y_train,loo_train,label=\"LOO\",color=\"black\",marker=\".\",facecolor='none',s=150)\n",
    "    plt.scatter(y_train,y_pred_train,label=\"training\",color=\"#1d0ba3\",marker=\".\",s=150,alpha=0.75)\n",
    "    plt.scatter(y_test,y_pred_test,label=\"test\",color=\"#ab1513\",marker=\".\",s=150,alpha=0.75)\n",
    "    plt.plot(y_train,yy_fit_line,color=\"black\",alpha=0.4)\n",
    "    if leg:\n",
    "        plt.legend(loc='lower right',fontsize=10)\n",
    "    plt.xlabel(\"measured \"+label,fontsize=14)\n",
    "    plt.ylabel(\"predicted \"+label,fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    if not sav:\n",
    "        plt.show()  \n",
    "    else:\n",
    "        plt.savefig(sav)\n",
    "\n",
    "def plot_fit_screen(y_train,y_pred_train,leg=True,sav=False,label=\"y\",loo_pred=[]):\n",
    "    y_orig_min = np.min(y_train)\n",
    "    y_pred_min = np.min(y_pred_train)\n",
    "    y_orig_max = np.max(y_train)\n",
    "    y_pred_max = np.max(y_pred_train)\n",
    "    delta_x = 0.04 * (y_orig_max-y_orig_min)\n",
    "    delta_y = 0.04 * (y_pred_max-y_pred_min)\n",
    "    yy_fit = np.polyfit(y_train,y_pred_train,deg=1)\n",
    "    yy_fit_line = yy_fit[1]+yy_fit[0]*y_train\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.xlim([y_orig_min-delta_x,y_orig_max+delta_x])\n",
    "    plt.ylim([y_pred_min-delta_y,y_pred_max+delta_y])\n",
    "    if len(loo_pred) != 0:\n",
    "        plt.scatter(y_train,loo_train,label=\"LOO\",color=\"black\",marker=\".\",facecolor='none',s=100)\n",
    "    plt.scatter(y_train,y_pred_train,label=\"training\",color=\"b\",marker=\".\",s=100,alpha=0.75)\n",
    "    plt.plot(y_train,yy_fit_line,color=\"black\",alpha=0.4)\n",
    "    if leg:\n",
    "        plt.legend(loc='lower right')\n",
    "    plt.xlabel(label+\" measured\",fontsize=10)\n",
    "    plt.ylabel(label+\" predicted\",fontsize=10)\n",
    "    if not sav:\n",
    "        plt.show()  \n",
    "    else:\n",
    "        plt.savefig(sav)      \n",
    "        \n",
    "def r2_val_2(y_test,y_pred_test):\n",
    "    y_resid = y_test - y_pred_test\n",
    "    SS_resid = np.sum(y_resid**2)\n",
    "    y_var = y_test - np.mean(y_test)\n",
    "    SS_total = np.sum(y_var**2)\n",
    "    r2_validation = 1-SS_resid/SS_total\n",
    "    return(r2_validation)\n",
    "\n",
    "def repeated_k_fold(X_train,y_train,reg = LinearRegression(), k=3, n=100):\n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n)\n",
    "    r2_scores = []\n",
    "    y_validations,y_predictions = np.zeros((np.shape(X_train)[0],n)),np.zeros((np.shape(X_train)[0],n))\n",
    "    foldcount = 0\n",
    "    for i,foldsplit in enumerate(rkf.split(X_train)):\n",
    "        fold, rep = i%k, int(i/k) # Which of k folds. Which of n repeats\n",
    "        model = reg.fit(X_train[foldsplit[0]],y_train[foldsplit[0]]) # foldsplit[0]: k-1 training folds\n",
    "        y_validations[foldcount:foldcount+len(foldsplit[1]),rep] = y_train[foldsplit[1]] # foldsplit[1]: validation fold\n",
    "        y_predictions[foldcount:foldcount+len(foldsplit[1]),rep]  = model.predict(X_train[foldsplit[1]])\n",
    "        foldcount += len(foldsplit[1])\n",
    "        if fold+1==k:\n",
    "            foldcount = 0\n",
    "    r2_scores = np.asarray([metrics.r2_score(y_validations[:,rep],y_predictions[:,rep]) for rep in range(n)])\n",
    "    return(r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:53:07.949259Z",
     "start_time": "2021-07-23T21:53:07.943873Z"
    }
   },
   "outputs": [],
   "source": [
    "comp_file = \"gen_descriptors\"\n",
    "comp_sheet = \"Sheet1\"\n",
    "num_par = 190\n",
    "par_start_col = 2\n",
    "comp_num_samples = 1560\n",
    "y_label_col_comp = 0 \n",
    "\n",
    "exp_file = \"gen_rxn_data\"\n",
    "exp_sheet = \"Phosphines\"\n",
    "exp_num_samples = 1776\n",
    "response_col = 6\n",
    "y_label_col_exp = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:53:16.789238Z",
     "start_time": "2021-07-23T21:53:12.048391Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compinp = pd.read_excel(comp_file+\".xlsx\",comp_sheet,header=0,index_col=y_label_col_comp,nrows=comp_num_samples+1,usecols=list(range(0,(num_par+par_start_col))),engine='openpyxl')\n",
    "compinp = compinp.drop(['smiles'],axis=1)\n",
    "par_start_col = 1\n",
    "compinp.index = compinp.index.map(str)\n",
    "\n",
    "expinp = pd.read_excel(exp_file+\".xlsx\",exp_sheet,header=2,index_col=y_label_col_exp,nrows=exp_num_samples,usecols=list(range(0,response_col+1)),engine='openpyxl')\n",
    "\n",
    "X_names = list(compinp.iloc[0,par_start_col-1:num_par+par_start_col-1])\n",
    "X_labels = list(compinp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "compinp.drop(index=compinp.index[0],inplace=True)\n",
    "X_all = np.asarray(compinp[X_labels],dtype=float)\n",
    "y_labels_comp = np.asarray(list(compinp.index),dtype=str)\n",
    "compnan = np.isnan(X_all).any(axis=1)\n",
    "y_labels_comp,X_all = y_labels_comp[~compnan],X_all[~compnan]\n",
    "X_labelname = [\" \".join(i) for i in zip(X_labels,X_names)]\n",
    "X_labelname_dict = dict(zip(X_labels,X_names))\n",
    "resp_label = list(expinp.columns)[response_col-1]\n",
    "y = np.asarray(expinp.iloc[:,response_col-1],dtype=float)\n",
    "y_labels_exp = np.asarray(list(expinp.index),dtype=str)\n",
    "mask_y = y.nonzero()[0]\n",
    "mask_y = ~np.isnan(y)\n",
    "mask_X = np.array([True if i in y_labels_comp else False for i in y_labels_exp])\n",
    "mask = mask_y&mask_X\n",
    "\n",
    "print(\"Number of entries in experimental file before removing empty cells: {}\".format(len(y)))\n",
    "print(\"Removing {} entries with empty cells\".format(len(y)-sum(mask)))\n",
    "\n",
    "y = y[np.array(mask)]\n",
    "y_labels = y_labels_exp[np.array(mask)]\n",
    "X = np.asarray(compinp.loc[y_labels],dtype=float)\n",
    "\n",
    "print(\"Shape of descriptors file for all ligands: {}\".format(X_all.shape))\n",
    "print(\"Last three ids in the descriptor file: {}\".format(y_labels_comp[-3:]))\n",
    "print(\"Shape of descriptors file for ligands with experimental results: {}\".format(X.shape))\n",
    "print(\"Shape of results file results (only ligands with experimental results): {}\".format(y.shape)) \n",
    "print(\"Shape of results file labels (only ligands with experimental results): {}\".format(y_labels.shape))\n",
    "print(\"First descriptor cell (for ligands with experimental results): {}\".format(X[0,0]))\n",
    "print('Ligands with results:',y_labels)\n",
    "print('Experimental results:',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Univariate correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:53:21.874730Z",
     "start_time": "2021-07-23T21:53:21.389253Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### All features:\n",
    "#features = range(np.shape(X)[1])\n",
    "\n",
    "### Features by X-numbers (1-indexed):\n",
    "features_x = [\"x92\"]\n",
    "features = [X_labels.index(i) for i in features_x]\n",
    "\n",
    "r2_cutoff = 0.0\n",
    "r2_values = []\n",
    "\n",
    "for f_ind in features:\n",
    "    feature = X_labels[f_ind]\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(X[:,f_ind], y)\n",
    "    fit_line = intercept+slope*X[:,f_ind]\n",
    "    r2 = r_value**2\n",
    "    r2_values.append(r2)\n",
    "    if r2 > r2_cutoff:\n",
    "        print(feature, X_names[f_ind])\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.hist(X[:,f_ind], bins=\"auto\")\n",
    "        plt.ylabel(\"frequency\",fontsize=12)\n",
    "        plt.xlabel(X_names[f_ind],fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.subplot(1,2,2)\n",
    "        sns.regplot(x=X[:,f_ind], y=y, ci=95, truncate=False)\n",
    "        x_max=np.max(X[:,f_ind])\n",
    "        x_min=np.min(X[:,f_ind])\n",
    "        y_max=np.max(y)\n",
    "        y_min=np.min(y)\n",
    "        delta_x = 0.05 * (x_max-x_min)\n",
    "        delta_y = 0.05 * (y_max-y_min)      \n",
    "        plt.xlim([x_min-delta_x,x_max+delta_x])\n",
    "        plt.ylim([y_min-delta_y,y_max+delta_y])\n",
    "        plt.xlabel(X_names[f_ind],fontsize=18)\n",
    "        plt.ylabel(\"Selectivity (ddG)\",fontsize=18)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        if p_value > 0.01:\n",
    "            print(\"R^2 = {:.2f}; p-value = {:.2f}\".format(r_value**2,p_value))\n",
    "        else:\n",
    "            print(\"R^2 = {:.2f}; p-value = {:.2E}\".format(r_value**2,p_value))\n",
    "        print(\"\\n-------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training/test set split and feature scaling**\n",
    "\n",
    "Methods to split the data:\n",
    "- 'random'\n",
    "- 'y_equidist': picks points that evenly span the output variable y. Normally doesn't pick highest/lowest values but this can be activated by changing the variable no_extrapolation in the respective section.\n",
    "- 'ks': Kennard Stone algorithm picks points based on an even distriution in feature space\n",
    "- 'define': give a list of sample indices for either VS or TS in the corresponding code section \n",
    "- 'none': all samples in TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:53:25.774762Z",
     "start_time": "2021-07-23T21:53:25.535125Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_sel,y_sel,labels_sel,exclude = X,y,y_labels,[]\n",
    "\n",
    "split = \"y_equidist\"\n",
    "test_ratio = 0.25\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "if split == \"random\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sel, y_sel, random_state=randomstate+3, test_size=test_ratio)    \n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test] \n",
    "elif split == \"define\":\n",
    "    TS = [1,2,3]\n",
    "    TS = [i-1 for i in VS]\n",
    "    VS = [i for i in range(X.shape[0]) if i not in VS and i not in exclude]\n",
    "    X_train, y_train,X_test, y_test = X[TS],y[TS],X[VS],y[VS] \n",
    "elif split == \"ks\":\n",
    "    TS,VS = fsc.kennardstonealgorithm(X_sel,int((1-test_ratio)*np.shape(X_sel)[0]))\n",
    "    X_train, y_train,X_test, y_test = X_sel[TS], y_sel[TS],X_sel[VS], y_sel[VS]\n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]   \n",
    "elif split == \"y_equidist\":\n",
    "    no_extrapolation = True\n",
    "    if no_extrapolation:\n",
    "        minmax = [np.argmin(y_sel),np.argmax(y_sel)]\n",
    "        y_ks = np.array(([i for i in y_sel if i not in [np.min(y_sel),np.max(y_sel)]]))\n",
    "        y_ks_indices = [i for i in range(len(y_sel)) if i not in minmax]\n",
    "        VS_ks,TS_ks = fsc.kennardstonealgorithm(y_ks.reshape(np.shape(y_ks)[0],1),int((test_ratio)*(2+np.shape(y_ks)[0])))\n",
    "        TS_ = sorted([y_ks_indices[i] for i in list(TS_ks)]+minmax)\n",
    "        VS_ = sorted([y_ks_indices[i] for i in VS_ks])\n",
    "    else:\n",
    "        VS_,TS_ = fsc.kennardstonealgorithm(y_sel.reshape(np.shape(y_sel)[0],1),int((test_ratio)*np.shape(y_sel)[0]))\n",
    "    X_train, y_train,X_test, y_test = X_sel[TS_], y_sel[TS_],X_sel[VS_], y_sel[VS_]\n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]\n",
    "elif split == \"none\":\n",
    "    TS, VS = [i for i in range(X.shape[0]) if i not in exclude],[]\n",
    "    X_train, y_train,X_test, y_test = X[TS],y[TS],X[VS],y[VS]  \n",
    "else: \n",
    "    raise ValueError(\"split option not recognized\")\n",
    "     \n",
    "print(\"TS: {}\".format(TS))\n",
    "print(\"VS: {}\".format(VS))\n",
    "print(\"y_mean TS: {:.3f}\".format(np.mean(y_train)))\n",
    "print(\"y_mean VS: {:.3f}\".format(np.mean(y_test)))\n",
    "print(\"Shape X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape X_test:  {}\".format(X_test.shape))   \n",
    "plt.figure(figsize=(5, 5))\n",
    "hist,bins = np.histogram(y_sel,bins=\"auto\")#\"auto\"\n",
    "plt.hist(y_train, bins, alpha=0.5, label='y_train',color=\"black\")\n",
    "plt.hist(y_test, bins, alpha=0.5, label='y_test')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"y\",fontsize=20)\n",
    "plt.ylabel(\"N samples\",fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:53:40.382653Z",
     "start_time": "2021-07-23T21:53:40.376665Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "X_all_sc = scaler.transform(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward stepwise selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:58:57.114270Z",
     "start_time": "2021-07-23T21:53:54.205229Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skipfeatures = []\n",
    "df = pd.DataFrame(np.hstack((X_train_sc,y_train[:,None])))\n",
    "newcols = [\"x\"+str(i+1) for i in df.columns.values]\n",
    "df.columns = newcols\n",
    "response = newcols[-1]\n",
    "df.rename(columns={response:\"y\"},inplace=True)\n",
    "df.drop(skipfeatures,axis=1,inplace=True)\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "# define variables for f.s.s.\n",
    "\n",
    "n_steps = 5             # no. of terms (do one more than the number you want; consequence of the algorithm)\n",
    "n_candidates = 15       # 10 or 15 usually\n",
    "collin_criteria = 0.5   # the maximum R2 between terms\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "results,models,scores,sortedmodels,candidates = fsc.ForwardStep_py(df,'y',\n",
    "                    n_steps=n_steps,n_candidates=n_candidates,collin_criteria=collin_criteria)\n",
    "model_sel = results.loc[0,\"Model\"]\n",
    "selected_feats = [X_labels.index(i) for i in models[model_sel].terms]\n",
    "print(\"\\n\\nBest model:\")\n",
    "print(models[model_sel].formula)\n",
    "print(\"1 + \"+\" + \".join([X_names[X_labels.index(i)] for i in models[candidates[0]].terms])+\"\\n\")\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "print(\"Parameters and coefficients:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[selected_feats[i]]) for i in range(len(selected_feats))]))\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "print(f\"\\nTest R2   = {r2_val_2(y_test,y_pred_test):.3f}\")\n",
    "print(f\"Test MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=True,sav=False,label=\"y\",loo_pred=loo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate test R2 for models in results and filter the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:59:21.297983Z",
     "start_time": "2021-07-23T21:59:19.386437Z"
    }
   },
   "outputs": [],
   "source": [
    "test_R2s = []\n",
    "for i in range(0,len(results)):\n",
    "    model_sel = results.loc[i,\"Model\"]\n",
    "    selected_feats = [X_labels.index(j) for j in models[model_sel].terms]\n",
    "    X_train_sel = X_train_sc[:,selected_feats]\n",
    "    X_test_sel = X_test_sc[:,selected_feats]\n",
    "    lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "    y_pred_train = lr.predict(X_train_sel)\n",
    "    y_pred_test =  lr.predict(X_test_sel)\n",
    "    test_R2 = r2_val_2(y_test,y_pred_test)\n",
    "    test_R2s.append(test_R2)\n",
    "results['test_R2'] = test_R2s\n",
    "results['diff_R2'] = results['R^2']-results['test_R2']\n",
    "results['diff_Q2'] = results['R^2']-results['Q^2']\n",
    "results2 = results.sort_values(ascending=False,by=['test_R2'])\n",
    "validatedmodels = results[results.n_terms<=4][results.test_R2>0.75][results.diff_Q2<0.1][results.diff_R2<0.1][results.diff_R2>0].sort_values(by=['test_R2'],ascending=False)\n",
    "print('Number of models =',len(validatedmodels))\n",
    "validatedmodels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize a specific model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:59:26.142176Z",
     "start_time": "2021-07-23T21:59:25.633231Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_sel = results.loc[0,\"Model\"]\n",
    "#model_sel = ('x1', 'x127','x183')\n",
    "\n",
    "selected_feats = [X_labels.index(i) for i in models[model_sel].terms]\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[selected_feats[i]]) for i in range(len(selected_feats))]))\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val_2(y_test,y_pred_test):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=True,sav=False,label=\" selectivity\",loo_pred=loo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Virtual screening setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:59:39.302162Z",
     "start_time": "2021-07-23T21:59:34.497557Z"
    }
   },
   "outputs": [],
   "source": [
    "ci = pd.read_excel('gen_descriptors.xlsx','Sheet1',index_col=0,header=1,engine='openpyxl')\n",
    "compinp = ci[ci.columns[1:-3]].loc[ci.index[:]]\n",
    "compinp.index = compinp.index.astype(int)\n",
    "compinp.dropna(axis=0,inplace=True)\n",
    "inp2 = pd.read_excel(\"gen_identifiers.xlsx\",index_col=1,header=2,engine='openpyxl')\n",
    "inp2.index = inp2.index.astype(int)\n",
    "X_all = np.array(compinp)\n",
    "X_gen_considered = np.array(compinp.loc[inp2[\"gen_considered\"]==1])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_all)\n",
    "X_all_sc    = scaler.transform(X_all)\n",
    "X_gen_considered_sc = scaler.transform(X_gen_considered)\n",
    "X_all_ids = np.array(compinp.index)\n",
    "X_gen_considered_ids = np.array(compinp.loc[inp2[\"gen_considered\"]==1].index)\n",
    "X_all_names = np.array(inp2[\"ligand\"].loc[X_all_ids])\n",
    "X_gen_considered_names = np.array(inp2['ligand'].loc[X_gen_considered_ids])\n",
    "print('Number of samples in original training set = ',len(y_train))\n",
    "y_train = np.concatenate((y_train,y_test), axis=0)\n",
    "X_train_sc = np.concatenate((X_train_sc,X_test_sc), axis=0)\n",
    "print('Number of samples in updated training set = ',len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose the subset to virtually screen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:08.390547Z",
     "start_time": "2021-07-23T22:00:08.386706Z"
    }
   },
   "outputs": [],
   "source": [
    "X_screen_sc = X_gen_considered_sc\n",
    "X_ids = X_gen_considered_ids.astype(str)\n",
    "X_names = X_gen_considered_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove ligands based on feature values**\n",
    "\n",
    "Values chosen based on threshold analysis of HTE reactivity results; vmin_vmin_boltz (x1) over -0.07 and vbur_vbur_min (x87) under 58.22. Ligands must pass both thresholds to be considered for screening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:10.634319Z",
     "start_time": "2021-07-23T22:00:10.620741Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_filter = X_gen_considered    # choose the subset to filter\n",
    "X_filter_sc = X_gen_considered_sc\n",
    "X_filter_ids = X_gen_considered_ids.astype(str)\n",
    "X_filter_names = X_gen_considered_names\n",
    "\n",
    "X_filtered_screen_sc = []\n",
    "X_filtered_ids = []\n",
    "X_filtered_names = []\n",
    "x1_count = 0\n",
    "x87_count = 0\n",
    "for i in range(0,len(X_filter_sc)):\n",
    "    count = 0\n",
    "    if X_filter[i][0] > -0.07:\n",
    "        count += 1\n",
    "    else:\n",
    "        x1_count += 1\n",
    "    if X_filter[i][86] < 58.22:\n",
    "        count += 1\n",
    "    else:\n",
    "        x87_count += 1\n",
    "    if count == 2:\n",
    "        X_filtered_screen_sc.append(X_filter_sc[i])\n",
    "        X_filtered_ids.append(X_filter_ids[i])\n",
    "        X_filtered_names.append(X_filter_names[i])\n",
    "    else:\n",
    "        pass\n",
    "X_filtered_screen_sc = np.asarray(X_filtered_screen_sc)\n",
    "X_filtered_ids = np.asarray(X_filtered_ids) \n",
    "X_filtered_names = np.asarray(X_filtered_names) \n",
    "X_screen_sc = X_filtered_screen_sc\n",
    "X_ids = X_filtered_ids\n",
    "X_names = X_filtered_names\n",
    "print(len(X_filter_sc),'ligands originally')\n",
    "print(len(X_screen_sc),'after filtering, these should match:',len(X_ids),'and',len(X_names))\n",
    "print(x1_count,'ligands failed x1 threshold')\n",
    "print(x87_count,'ligands failed x87 threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Virtually screen using multiple models: Set up the correlation map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:18.383328Z",
     "start_time": "2021-07-23T22:00:14.205614Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "par_start_col = 2\n",
    "compinp2 = pd.read_excel(comp_file+\".xlsx\",comp_sheet,header=0,index_col=y_label_col_comp,nrows=comp_num_samples+1,usecols=list(range(0,(num_par+par_start_col))),engine='openpyxl')\n",
    "compinp2 = compinp2.drop(['smiles'],axis=1)\n",
    "compinp2.index = compinp2.index.map(str)\n",
    "compinp2.drop(index=compinp2.index[0],inplace=True)\n",
    "compinp2.reset_index(level=0, inplace=True)\n",
    "compinp2 = compinp2.drop(columns='x')\n",
    "compinp2 = compinp2.astype(float)\n",
    "corr_map = compinp2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the set of models for virtual screening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:21.043069Z",
     "start_time": "2021-07-23T22:00:21.033696Z"
    }
   },
   "outputs": [],
   "source": [
    "data_top = validatedmodels.head(100)\n",
    "best_models = list(data_top.index)\n",
    "best_models_formulae = list(data_top['Model'])\n",
    "best_models_ids_formulae = []\n",
    "for i in range(0,len(best_models)):\n",
    "    x = best_models[i]\n",
    "    y = best_models_formulae[i]\n",
    "    z = [x,y]\n",
    "    best_models_ids_formulae.append(z)\n",
    "print('len best_models =',len(best_models))\n",
    "print('best_models =',best_models)\n",
    "print('')\n",
    "keep_models = []\n",
    "keep_models.append(best_models[0])\n",
    "print('keep_models =',keep_models)\n",
    "keep_models_formulae = []\n",
    "keep_models_formulae.append(best_models_formulae[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove collinear models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:24.301410Z",
     "start_time": "2021-07-23T22:00:24.121190Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "collin_criteria = 0.5\n",
    "\n",
    "collin_criteria = np.sqrt(collin_criteria)\n",
    "for i in best_models_formulae:\n",
    "    add_bm = []\n",
    "    for j in keep_models_formulae:                               \n",
    "        bm_colin_feat=[]\n",
    "        bm = list(i)                                 \n",
    "        km = list(j)\n",
    "        new_bm = [a for a in bm if a not in km]\n",
    "        new_km = [b for b in km if b not in bm]\n",
    "        for k in new_bm:\n",
    "            for l in new_km:\n",
    "                colinearity = abs(corr_map.loc[k,l])\n",
    "                if colinearity>collin_criteria:\n",
    "                    x = [k,l]\n",
    "                    bm_colin_feat.append(x)\n",
    "                else:\n",
    "                    pass\n",
    "        if not new_bm:\n",
    "            pass\n",
    "        else:        \n",
    "            for m in range(0,len(bm_colin_feat)):\n",
    "                try:\n",
    "                    new_bm.remove(bm_colin_feat[m][0])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            if not new_bm:\n",
    "                add_bm.append('dont add')\n",
    "            else:\n",
    "                add_bm.append('do add')\n",
    "    if not add_bm:\n",
    "        pass\n",
    "    elif 'dont add' in add_bm:\n",
    "        pass\n",
    "    else:\n",
    "        keep_models_formulae.append(i)\n",
    "            \n",
    "print('len bmf = ',len(best_models_formulae))\n",
    "print('len kmf = ',len(keep_models_formulae))\n",
    "new_best_models = []\n",
    "for i in range(0,len(best_models_ids_formulae)):\n",
    "    for j in range(0,len(keep_models_formulae)):\n",
    "        if best_models_ids_formulae[i][1] == keep_models_formulae[j]:\n",
    "            new_best_models.append(best_models_ids_formulae[i][0])     \n",
    "print('len new_best_models = ',len(new_best_models))\n",
    "print('new_best_models = ',new_best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Virtually screen using the defined set of models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:27.639208Z",
     "start_time": "2021-07-23T22:00:26.677303Z"
    }
   },
   "outputs": [],
   "source": [
    "X_combined = []\n",
    "for i in range(0,len(X_ids)):\n",
    "    j = str(X_names[i]) + \" (ID \" + X_ids[i] + \")\"\n",
    "    X_combined.append(j)\n",
    "headings = ['Ligand']\n",
    "for i in range(0,len(new_best_models)):\n",
    "    j = 'model ' + str(new_best_models[i])\n",
    "    headings.append(j)    \n",
    "print('minimum actual response value =',min(y_train))\n",
    "print('maximum actual response value =',max(y_train))\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.xticks(fontsize=12.5) \n",
    "plt.yticks(fontsize=12.5)\n",
    "plt.xlabel(\"ligand\",fontsize=15,labelpad=20)\n",
    "plt.ylabel(\"predicted ln(Z/E)\",fontsize=15,labelpad=5)\n",
    "plt.tick_params(axis='x', labelbottom=False)\n",
    "training_R2s = []\n",
    "pred_results = {'ligands': X_combined}\n",
    "for i in new_best_models:\n",
    "    model_sel = results.loc[i,\"Model\"]\n",
    "    selected_feats = [X_labels.index(i) for i in models[model_sel].terms]\n",
    "    X_train_sel = X_train_sc[:,selected_feats]\n",
    "    X_screen_sel = X_screen_sc[:,selected_feats]\n",
    "    lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "    y_pred_train = lr.predict(X_train_sel)\n",
    "    y_pred_screen =  lr.predict(X_screen_sel)\n",
    "    training_R2s.append(lr.score(X_train_sel, y_train))\n",
    "    plt.plot(X_combined, y_pred_screen, color=\"black\", label = 'model '+str(i), alpha = 0.2)\n",
    "    pred_results[str(i)] = y_pred_screen\n",
    "print('')    \n",
    "print('Training R2 for best model =',training_R2s[0])\n",
    "print('Training R2 for worst model =',training_R2s[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T19:31:21.644425Z",
     "start_time": "2020-10-10T19:31:21.636681Z"
    }
   },
   "source": [
    "**df of all the predicted results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:33.617747Z",
     "start_time": "2021-07-23T22:00:31.046687Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(pred_results)\n",
    "df1 = df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "df1.set_properties(**{'text-align': 'center'}).hide_index()\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing the predicted selectivities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:38.278189Z",
     "start_time": "2021-07-23T22:00:38.259072Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(pred_results)\n",
    "df = df.set_index('ligands')\n",
    "df['average'] = df.mean(axis=1)\n",
    "df['std_dev'] = df.std(axis=1)\n",
    "df = df.filter(['average','std_dev'])\n",
    "df_2 = df[df.std_dev<0.3]\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ligands with predicted selectivities below the experimental minimum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:41.719605Z",
     "start_time": "2021-07-23T22:00:41.709975Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Minimum experimental result = ',min(y_train))\n",
    "df_low = df_2.copy()\n",
    "df_low = df_low[df_low.average < min(y_train)]\n",
    "df_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ligands with predicted selectivities above the experimental maximum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:00:44.558947Z",
     "start_time": "2021-07-23T22:00:44.549911Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Maximum experimental result = ',max(y_train))\n",
    "df_high = df_2.copy()\n",
    "df_high = df_high[df_high.average > max(y_train)]\n",
    "df_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
